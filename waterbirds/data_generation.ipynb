{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageFilter\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from skimage.util import random_noise\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "from dataset_utils import crop_and_resize, combine_and_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CUB_DIR = '../data/cub-200-2011'\n",
    "PLACES_DIR = '../data/val_large'\n",
    "OUTPUT_DIR = '../data/dataset'\n",
    "DATASET_NAME = 'places_validation_waterbird_95_segout'\n",
    "BACKGROUND_AUG = False\n",
    "SEGMENTATION_AS_INPUT = False\n",
    "SEGMENTATION_AS_OUTPUT = True\n",
    "\n",
    "target_places_ids = [\n",
    "    [36, 150],  # Land backgrounds ['bamboo_forest', 'forest/broadleaf']\n",
    "    [243, 205]] # Water backgrounds ['ocean', 'lake/natural']\n",
    "\n",
    "val_frac = 0.2             # What fraction of the training data to use as validation\n",
    "confounder_strength = 0.95 # Determines relative size of majority vs. minority groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "waterbirds are 0.228 of the examples\n",
      "y = 0, c = 0: 0.950, n = 3518\n",
      "y = 0, c = 1: 0.050, n = 185\n",
      "y = 1, c = 0: 0.050, n = 55\n",
      "y = 1, c = 1: 0.950, n = 1037\n",
      "val:\n",
      "waterbirds are 0.239 of the examples\n",
      "y = 0, c = 0: 0.950, n = 866\n",
      "y = 0, c = 1: 0.050, n = 46\n",
      "y = 1, c = 0: 0.049, n = 14\n",
      "y = 1, c = 1: 0.951, n = 273\n",
      "test:\n",
      "waterbirds are 0.222 of the examples\n",
      "y = 0, c = 0: 0.500, n = 2255\n",
      "y = 0, c = 1: 0.500, n = 2255\n",
      "y = 1, c = 0: 0.500, n = 642\n",
      "y = 1, c = 1: 0.500, n = 642\n"
     ]
    }
   ],
   "source": [
    "images_path = os.path.join(CUB_DIR,'CUB_200_2011', 'CUB_200_2011', 'images.txt')\n",
    "\n",
    "df = pd.read_csv(\n",
    "    images_path,\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['img_id', 'img_filename'],\n",
    "    index_col='img_id')\n",
    "\n",
    "### Set up labels of waterbirds vs. landbirds\n",
    "# We consider water birds = seabirds and waterfowl.\n",
    "species = np.unique([img_filename.split('/')[0].split('.')[1].lower() for img_filename in df['img_filename']])\n",
    "water_birds_list = [\n",
    "    'Albatross', # Seabirds\n",
    "    'Auklet',\n",
    "    'Cormorant',\n",
    "    'Frigatebird',\n",
    "    'Fulmar',\n",
    "    'Gull',\n",
    "    'Jaeger',\n",
    "    'Kittiwake',\n",
    "    'Pelican',\n",
    "    'Puffin',\n",
    "    'Tern',\n",
    "    'Gadwall', # Waterfowl\n",
    "    'Grebe',\n",
    "    'Mallard',\n",
    "    'Merganser',\n",
    "    'Guillemot',\n",
    "    'Pacific_Loon'\n",
    "]\n",
    "\n",
    "water_birds = {}\n",
    "for species_name in species:\n",
    "    water_birds[species_name] = 0\n",
    "    for water_bird in water_birds_list:\n",
    "        if water_bird.lower() in species_name:\n",
    "            water_birds[species_name] = 1\n",
    "species_list = [img_filename.split('/')[0].split('.')[1].lower() for img_filename in df['img_filename']]\n",
    "df['y'] = [water_birds[species] for species in species_list]\n",
    "\n",
    "### Assign train/tesst/valid splits\n",
    "# In the original CUB dataset split, split = 0 is test and split = 1 is train\n",
    "# We want to change it to\n",
    "# split = 0 is train,\n",
    "# split = 1 is val,\n",
    "# split = 2 is test\n",
    "\n",
    "train_test_df =  pd.read_csv(\n",
    "    os.path.join(CUB_DIR, 'CUB_200_2011', 'CUB_200_2011', 'train_test_split.txt'),\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['img_id', 'split'],\n",
    "    index_col='img_id')\n",
    "\n",
    "df = df.join(train_test_df, on='img_id')\n",
    "test_ids = df.loc[df['split'] == 0].index\n",
    "train_ids = np.array(df.loc[df['split'] == 1].index)\n",
    "val_ids = np.random.choice(\n",
    "    train_ids,\n",
    "    size=int(np.round(val_frac * len(train_ids))),\n",
    "    replace=False)\n",
    "\n",
    "df.loc[train_ids, 'split'] = 0\n",
    "df.loc[val_ids, 'split'] = 1\n",
    "df.loc[test_ids, 'split'] = 2\n",
    "\n",
    "### Assign confounders (place categories)\n",
    "\n",
    "# Confounders are set up as the following:\n",
    "# Y = 0, C = 0: confounder_strength\n",
    "# Y = 0, C = 1: 1 - confounder_strength\n",
    "# Y = 1, C = 0: 1 - confounder_strength\n",
    "# Y = 1, C = 1: confounder_strength\n",
    "\n",
    "df['place'] = 0\n",
    "train_ids = np.array(df.loc[df['split'] == 0].index)\n",
    "val_ids = np.array(df.loc[df['split'] == 1].index)\n",
    "test_ids = np.array(df.loc[df['split'] == 2].index)\n",
    "for split_idx, ids in enumerate([train_ids, val_ids, test_ids]):\n",
    "    for y in (0, 1):\n",
    "        if split_idx == 0: # train\n",
    "            if y == 0:\n",
    "                pos_fraction = 1 - confounder_strength\n",
    "            else:\n",
    "                pos_fraction = confounder_strength\n",
    "        elif split_idx == 1: # val\n",
    "            if y == 0:\n",
    "                pos_fraction = 1 - confounder_strength\n",
    "            else:\n",
    "                pos_fraction = confounder_strength\n",
    "        else: #test\n",
    "            pos_fraction = 0.5\n",
    "        subset_df = df.loc[ids, :]\n",
    "        y_ids = np.array((subset_df.loc[subset_df['y'] == y]).index)\n",
    "        pos_place_ids = np.random.choice(\n",
    "            y_ids,\n",
    "            size=int(np.round(pos_fraction * len(y_ids))),\n",
    "            replace=False)\n",
    "        df.loc[pos_place_ids, 'place'] = 1\n",
    "\n",
    "for split, split_label in [(0, 'train'), (1, 'val'), (2, 'test')]:\n",
    "    print(f\"{split_label}:\")\n",
    "    split_df = df.loc[df['split'] == split, :]\n",
    "    print(f\"waterbirds are {np.mean(split_df['y']):.3f} of the examples\")\n",
    "    print(f\"y = 0, c = 0: {np.mean(split_df.loc[split_df['y'] == 0, 'place'] == 0):.3f}, n = {np.sum((split_df['y'] == 0) & (split_df['place'] == 0))}\")\n",
    "    print(f\"y = 0, c = 1: {np.mean(split_df.loc[split_df['y'] == 0, 'place'] == 1):.3f}, n = {np.sum((split_df['y'] == 0) & (split_df['place'] == 1))}\")\n",
    "    print(f\"y = 1, c = 0: {np.mean(split_df.loc[split_df['y'] == 1, 'place'] == 0):.3f}, n = {np.sum((split_df['y'] == 1) & (split_df['place'] == 0))}\")\n",
    "    print(f\"y = 1, c = 1: {np.mean(split_df.loc[split_df['y'] == 1, 'place'] == 1):.3f}, n = {np.sum((split_df['y'] == 1) & (split_df['place'] == 1))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign places to train, val, and test set\n",
    "place_ids_df = pd.read_csv(\n",
    "    os.path.join(PLACES_DIR, 'places365_val.txt'),\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['image_name', 'place_id'],\n",
    "    index_col='place_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_imgs = set()\n",
    "land_imgs = set()\n",
    "\n",
    "for i, place_type in enumerate(target_places_ids):\n",
    "    for id in place_type:\n",
    "        if i == 0:\n",
    "            land_imgs.update(place_ids_df[place_ids_df.index == id]['image_name'])\n",
    "        if i ==1:\n",
    "            water_imgs.update(place_ids_df[place_ids_df.index == id]['image_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['water_img'] = np.random.choice(list(water_imgs), size=len(df))\n",
    "df['land_img'] = np.random.choice(list(land_imgs), size=len(df))\n",
    "df['place_image'] = df['place']*df['water_img'] + (1-df['place'])*df['land_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11788/11788 [17:16<00:00, 11.38it/s]\n"
     ]
    }
   ],
   "source": [
    "### Write dataset to disk\n",
    "output_subfolder = os.path.join(OUTPUT_DIR, DATASET_NAME)\n",
    "os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "for i in tqdm(df.index):\n",
    "    # Load bird image and segmentation\n",
    "    img_path = os.path.join(CUB_DIR, 'CUB_200_2011', 'CUB_200_2011', 'images', df.loc[i, 'img_filename'])\n",
    "    seg_path = os.path.join(CUB_DIR, 'segmentations', df.loc[i, 'img_filename'].replace('.jpg','.png'))\n",
    "    img_np = np.asarray(Image.open(img_path).convert('RGB'))\n",
    "    seg_img = Image.open(seg_path).convert('RGB')\n",
    "    seg_np = np.asarray(seg_img) / 255\n",
    "\n",
    "    # Load place background\n",
    "    # Skip front /\n",
    "    place_path = os.path.join(PLACES_DIR, df.loc[i, 'place_image'])\n",
    "    place = Image.open(place_path).convert('RGB')\n",
    "\n",
    "    if BACKGROUND_AUG:\n",
    "        if df.loc[i, 'split'] == 0:\n",
    "            # place = gray2rgb(rgb2gray(np.array(place)))\n",
    "            place = random_noise(np.array(place), mode='gaussian', mean=0, var=0.05, clip=True)   \n",
    "            # place = random_noise(np.array(place), mode='s&p', salt_vs_pepper=0.5, clip=True)\n",
    "            # place = random_noise(np.array(place), mode='speckle', mean=0, var=0.05, clip=True)\n",
    "            place = Image.fromarray((place * 255).astype(np.uint8)) \n",
    "\n",
    "    img_black = Image.fromarray(np.around(img_np * seg_np).astype(np.uint8))\n",
    "    combined_img = combine_and_mask(place, seg_np, img_black)\n",
    "\n",
    "\n",
    "    if SEGMENTATION_AS_INPUT:\n",
    "        combined_img.putalpha(seg_img.convert(\"L\"))\n",
    "\n",
    "    label_folder = ''\n",
    "    if df.loc[i, 'y'] == 1:\n",
    "        label_folder = 'waterbird'\n",
    "    if df.loc[i, 'y'] == 0:\n",
    "        label_folder = 'landbird'\n",
    "\n",
    "    split_folder = ''\n",
    "    if df.loc[i, 'split'] == 0:\n",
    "        split_folder = 'train'\n",
    "    if df.loc[i, 'split'] == 1:\n",
    "        split_folder = 'val'\n",
    "    if df.loc[i, 'split'] == 2:\n",
    "        split_folder = 'test'\n",
    "    img_path_name = df.loc[i, 'img_filename'].split('/')[-1]\n",
    "\n",
    "    if SEGMENTATION_AS_OUTPUT:\n",
    "        output_path = os.path.join(output_subfolder, split_folder, 'image', img_path_name).replace('.jpg','.png')\n",
    "        os.makedirs(os.path.join(output_subfolder, split_folder, 'image'), exist_ok=True)\n",
    "        seg_output_path = os.path.join(output_subfolder, split_folder, 'mask', img_path_name).replace('.jpg','.png')\n",
    "        os.makedirs(os.path.join(output_subfolder, split_folder, 'mask'), exist_ok=True)\n",
    "        seg_img.save(seg_output_path)\n",
    "    else:\n",
    "        output_path = os.path.join(output_subfolder, split_folder, label_folder, img_path_name).replace('.jpg','.png')\n",
    "        os.makedirs(os.path.join(output_subfolder, split_folder, label_folder), exist_ok=True)\n",
    "\n",
    "    combined_img.save(output_path)\n",
    "    df.loc[i, 'img_filename'] = output_path\n",
    "\n",
    "df.to_csv(os.path.join(output_subfolder, 'metadata.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_subfolder = os.path.join(OUTPUT_DIR, \"water\")\n",
    "# os.makedirs(type_subfolder, exist_ok=True)\n",
    "\n",
    "# for img in water_imgs:\n",
    "#     place_path = os.path.join(PLACES_DIR, img)\n",
    "#     output_path = os.path.join(type_subfolder, img)\n",
    "#     place = Image.open(place_path).convert('RGB')\n",
    "#     place.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type_subfolder = os.path.join(OUTPUT_DIR, \"land\")\n",
    "# os.makedirs(type_subfolder, exist_ok=True)\n",
    "\n",
    "# for img in land_imgs:\n",
    "#     place_path = os.path.join(PLACES_DIR, img)\n",
    "#     output_path = os.path.join(type_subfolder, img)\n",
    "#     place = Image.open(place_path).convert('RGB')\n",
    "#     place.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_img = \"Places365_val_00000906.jpg\"\n",
    "bird = \"012.Yellow_headed_Blackbird/Yellow_Headed_Blackbird_0008_8756.jpg\"\n",
    "output_subfolder = os.path.join(OUTPUT_DIR, \"test\")\n",
    "os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "# Load bird image and segmentation\n",
    "img_path = os.path.join(CUB_DIR, 'CUB_200_2011', 'CUB_200_2011', 'images', bird)\n",
    "seg_path = os.path.join(CUB_DIR, 'segmentations', bird.replace('.jpg','.png'))\n",
    "img_np = np.asarray(Image.open(img_path).convert('RGB'))\n",
    "seg_np = np.asarray(Image.open(seg_path).convert('RGB')) / 255\n",
    "\n",
    "# Load place background\n",
    "# Skip front /\n",
    "place_path = os.path.join(PLACES_DIR, water_img)\n",
    "place = Image.open(place_path).convert('RGB')\n",
    "\n",
    "img_black = Image.fromarray(np.around(img_np * seg_np).astype(np.uint8))\n",
    "combined_img = combine_and_mask(place, seg_np, img_black)\n",
    "output_path = os.path.join(output_subfolder, \"original.jpg\")\n",
    "combined_img.save(output_path)\n",
    "\n",
    "gaussian_place = random_noise(np.array(place), mode='gaussian', mean=0, var=0.05, clip=True) \n",
    "gaussian_place = Image.fromarray((gaussian_place * 255).astype(np.uint8)) \n",
    "combined_img = combine_and_mask(gaussian_place, seg_np, img_black)\n",
    "output_path = os.path.join(output_subfolder, \"gaussian.jpg\")\n",
    "combined_img.save(output_path)\n",
    "\n",
    "sandp_place = random_noise(np.array(place), mode='s&p', salt_vs_pepper=0.5, clip=True)\n",
    "sandp_place = Image.fromarray((sandp_place * 255).astype(np.uint8)) \n",
    "combined_img = combine_and_mask(sandp_place, seg_np, img_black)\n",
    "output_path = os.path.join(output_subfolder, \"sandp.jpg\")\n",
    "combined_img.save(output_path)\n",
    "\n",
    "speckle_place = random_noise(np.array(place), mode='speckle', mean=0, var=0.05, clip=True)\n",
    "speckle_place = Image.fromarray((speckle_place * 255).astype(np.uint8)) \n",
    "combined_img = combine_and_mask(speckle_place, seg_np, img_black)\n",
    "output_path = os.path.join(output_subfolder, \"speckle.jpg\")\n",
    "combined_img.save(output_path)\n",
    "\n",
    "gray_place = gray2rgb(rgb2gray(np.array(place)))\n",
    "gray_place = Image.fromarray((gray_place * 255).astype(np.uint8)) \n",
    "combined_img = combine_and_mask(gray_place, seg_np, img_black)\n",
    "output_path = os.path.join(output_subfolder, \"gray.jpg\")\n",
    "combined_img.save(output_path)\n",
    "\n",
    "blur_place = place.filter(ImageFilter.BLUR)\n",
    "combined_img = combine_and_mask(blur_place, seg_np, img_black)\n",
    "output_path = os.path.join(output_subfolder, \"blur.jpg\")\n",
    "combined_img.save(output_path)\n",
    "\n",
    "# place = gray2rgb(rgb2gray(np.array(place)))\n",
    "        # place = random_noise(np.array(place), mode='s&p', salt_vs_pepper=0.5, clip=True)\n",
    "        # place = random_noise(np.array(place), mode='speckle', mean=0, var=0.05, clip=True)\n",
    "        # place = Image.fromarray((place * 255).astype(np.uint8))  "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
