{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from dataset_utils import crop_and_resize, combine_and_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cub_dir = '../data/cub-200-2011'\n",
    "places_dir = '../data/val_large'\n",
    "output_dir = '../data/dataset'\n",
    "dataset_name = 'validation_waterbird_50'\n",
    "\n",
    "target_places_ids = [\n",
    "    [36, 150],  # Land backgrounds ['bamboo_forest', 'forest/broadleaf']\n",
    "    [243, 205]] # Water backgrounds ['ocean', 'lake/natural']\n",
    "\n",
    "val_frac = 0.2             # What fraction of the training data to use as validation\n",
    "confounder_strength = 0.5 # Determines relative size of majority vs. minority groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "waterbirds are 0.227 of the examples\n",
      "y = 0, c = 0: 0.500, n = 1853\n",
      "y = 0, c = 1: 0.500, n = 1853\n",
      "y = 1, c = 0: 0.500, n = 545\n",
      "y = 1, c = 1: 0.500, n = 544\n",
      "val:\n",
      "waterbirds are 0.242 of the examples\n",
      "y = 0, c = 0: 0.501, n = 455\n",
      "y = 0, c = 1: 0.499, n = 454\n",
      "y = 1, c = 0: 0.500, n = 145\n",
      "y = 1, c = 1: 0.500, n = 145\n",
      "test:\n",
      "waterbirds are 0.222 of the examples\n",
      "y = 0, c = 0: 0.500, n = 2255\n",
      "y = 0, c = 1: 0.500, n = 2255\n",
      "y = 1, c = 0: 0.500, n = 642\n",
      "y = 1, c = 1: 0.500, n = 642\n"
     ]
    }
   ],
   "source": [
    "images_path = os.path.join(cub_dir,'CUB_200_2011', 'CUB_200_2011', 'images.txt')\n",
    "\n",
    "df = pd.read_csv(\n",
    "    images_path,\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['img_id', 'img_filename'],\n",
    "    index_col='img_id')\n",
    "\n",
    "### Set up labels of waterbirds vs. landbirds\n",
    "# We consider water birds = seabirds and waterfowl.\n",
    "species = np.unique([img_filename.split('/')[0].split('.')[1].lower() for img_filename in df['img_filename']])\n",
    "water_birds_list = [\n",
    "    'Albatross', # Seabirds\n",
    "    'Auklet',\n",
    "    'Cormorant',\n",
    "    'Frigatebird',\n",
    "    'Fulmar',\n",
    "    'Gull',\n",
    "    'Jaeger',\n",
    "    'Kittiwake',\n",
    "    'Pelican',\n",
    "    'Puffin',\n",
    "    'Tern',\n",
    "    'Gadwall', # Waterfowl\n",
    "    'Grebe',\n",
    "    'Mallard',\n",
    "    'Merganser',\n",
    "    'Guillemot',\n",
    "    'Pacific_Loon'\n",
    "]\n",
    "\n",
    "water_birds = {}\n",
    "for species_name in species:\n",
    "    water_birds[species_name] = 0\n",
    "    for water_bird in water_birds_list:\n",
    "        if water_bird.lower() in species_name:\n",
    "            water_birds[species_name] = 1\n",
    "species_list = [img_filename.split('/')[0].split('.')[1].lower() for img_filename in df['img_filename']]\n",
    "df['y'] = [water_birds[species] for species in species_list]\n",
    "\n",
    "### Assign train/tesst/valid splits\n",
    "# In the original CUB dataset split, split = 0 is test and split = 1 is train\n",
    "# We want to change it to\n",
    "# split = 0 is train,\n",
    "# split = 1 is val,\n",
    "# split = 2 is test\n",
    "\n",
    "train_test_df =  pd.read_csv(\n",
    "    os.path.join(cub_dir, 'CUB_200_2011', 'CUB_200_2011', 'train_test_split.txt'),\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['img_id', 'split'],\n",
    "    index_col='img_id')\n",
    "\n",
    "df = df.join(train_test_df, on='img_id')\n",
    "test_ids = df.loc[df['split'] == 0].index\n",
    "train_ids = np.array(df.loc[df['split'] == 1].index)\n",
    "val_ids = np.random.choice(\n",
    "    train_ids,\n",
    "    size=int(np.round(val_frac * len(train_ids))),\n",
    "    replace=False)\n",
    "\n",
    "df.loc[train_ids, 'split'] = 0\n",
    "df.loc[val_ids, 'split'] = 1\n",
    "df.loc[test_ids, 'split'] = 2\n",
    "\n",
    "### Assign confounders (place categories)\n",
    "\n",
    "# Confounders are set up as the following:\n",
    "# Y = 0, C = 0: confounder_strength\n",
    "# Y = 0, C = 1: 1 - confounder_strength\n",
    "# Y = 1, C = 0: 1 - confounder_strength\n",
    "# Y = 1, C = 1: confounder_strength\n",
    "\n",
    "df['place'] = 0\n",
    "train_ids = np.array(df.loc[df['split'] == 0].index)\n",
    "val_ids = np.array(df.loc[df['split'] == 1].index)\n",
    "test_ids = np.array(df.loc[df['split'] == 2].index)\n",
    "for split_idx, ids in enumerate([train_ids, val_ids, test_ids]):\n",
    "    for y in (0, 1):\n",
    "        if split_idx == 0: # train\n",
    "            if y == 0:\n",
    "                pos_fraction = 1 - confounder_strength\n",
    "            else:\n",
    "                pos_fraction = confounder_strength\n",
    "        else:\n",
    "            pos_fraction = 0.5\n",
    "        subset_df = df.loc[ids, :]\n",
    "        y_ids = np.array((subset_df.loc[subset_df['y'] == y]).index)\n",
    "        pos_place_ids = np.random.choice(\n",
    "            y_ids,\n",
    "            size=int(np.round(pos_fraction * len(y_ids))),\n",
    "            replace=False)\n",
    "        df.loc[pos_place_ids, 'place'] = 1\n",
    "\n",
    "for split, split_label in [(0, 'train'), (1, 'val'), (2, 'test')]:\n",
    "    print(f\"{split_label}:\")\n",
    "    split_df = df.loc[df['split'] == split, :]\n",
    "    print(f\"waterbirds are {np.mean(split_df['y']):.3f} of the examples\")\n",
    "    print(f\"y = 0, c = 0: {np.mean(split_df.loc[split_df['y'] == 0, 'place'] == 0):.3f}, n = {np.sum((split_df['y'] == 0) & (split_df['place'] == 0))}\")\n",
    "    print(f\"y = 0, c = 1: {np.mean(split_df.loc[split_df['y'] == 0, 'place'] == 1):.3f}, n = {np.sum((split_df['y'] == 0) & (split_df['place'] == 1))}\")\n",
    "    print(f\"y = 1, c = 0: {np.mean(split_df.loc[split_df['y'] == 1, 'place'] == 0):.3f}, n = {np.sum((split_df['y'] == 1) & (split_df['place'] == 0))}\")\n",
    "    print(f\"y = 1, c = 1: {np.mean(split_df.loc[split_df['y'] == 1, 'place'] == 1):.3f}, n = {np.sum((split_df['y'] == 1) & (split_df['place'] == 1))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Assign places to train, val, and test set\n",
    "place_ids_df = pd.read_csv(\n",
    "    os.path.join(places_dir, 'places365_val.txt'),\n",
    "    sep=\" \",\n",
    "    header=None,\n",
    "    names=['image_name', 'place_id'],\n",
    "    index_col='place_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_imgs = set()\n",
    "land_imgs = set()\n",
    "\n",
    "for i, place_type in enumerate(target_places_ids):\n",
    "    for id in place_type:\n",
    "        if i == 0:\n",
    "            land_imgs.update(place_ids_df[place_ids_df.index == id]['image_name'])\n",
    "        if i ==1:\n",
    "            water_imgs.update(place_ids_df[place_ids_df.index == id]['image_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['water_img'] = np.random.choice(list(water_imgs), size=len(df))\n",
    "df['land_img'] = np.random.choice(list(land_imgs), size=len(df))\n",
    "df['place_image'] = df['place']*df['water_img'] + (1-df['place'])*df['land_img']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11788/11788 [13:06<00:00, 14.98it/s] \n"
     ]
    }
   ],
   "source": [
    "### Write dataset to disk\n",
    "output_subfolder = os.path.join(output_dir, dataset_name)\n",
    "os.makedirs(output_subfolder, exist_ok=True)\n",
    "\n",
    "df.to_csv(os.path.join(output_subfolder, 'metadata.csv'))\n",
    "\n",
    "for i in tqdm(df.index):\n",
    "    # Load bird image and segmentation\n",
    "    img_path = os.path.join(cub_dir, 'CUB_200_2011', 'CUB_200_2011', 'images', df.loc[i, 'img_filename'])\n",
    "    seg_path = os.path.join(cub_dir, 'segmentations', df.loc[i, 'img_filename'].replace('.jpg','.png'))\n",
    "    img_np = np.asarray(Image.open(img_path).convert('RGB'))\n",
    "    seg_np = np.asarray(Image.open(seg_path).convert('RGB')) / 255\n",
    "\n",
    "    # Load place background\n",
    "    # Skip front /\n",
    "    place_path = os.path.join(places_dir, df.loc[i, 'place_image'])\n",
    "    place = Image.open(place_path).convert('RGB')\n",
    "\n",
    "    img_black = Image.fromarray(np.around(img_np * seg_np).astype(np.uint8))\n",
    "    combined_img = combine_and_mask(place, seg_np, img_black)\n",
    "\n",
    "    output_path = os.path.join(output_subfolder, df.loc[i, 'img_filename'])\n",
    "    os.makedirs('/'.join(output_path.split('/')[:-1]), exist_ok=True)\n",
    "\n",
    "    combined_img.save(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
