{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"segmentation_as_input.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMUVS1rxTmxMsWKSvaD4LgZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"586ae0288fbc480fb676e67d97359198":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_510678b2049340b5b239768474bc9b4d","IPY_MODEL_ad4f1c0bbe4f48b7b8ce69615ccbb330","IPY_MODEL_c220bf1d60cd4c8b982d4d965677b784"],"layout":"IPY_MODEL_367c1c2fd8dc4f53a86425fc81466451"}},"510678b2049340b5b239768474bc9b4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6f6abeb3a444085992b846d184aeb47","placeholder":"​","style":"IPY_MODEL_16904d3f67644c7d9e6ae77bca452a36","value":"100%"}},"ad4f1c0bbe4f48b7b8ce69615ccbb330":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6d5b81d0bfcc41258a7a8e101c6eab2e","max":46830571,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d6e8856985a34894b8fca3ba6dec4830","value":46830571}},"c220bf1d60cd4c8b982d4d965677b784":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1a988bd12c5c48e1a33fb7d1e2902c50","placeholder":"​","style":"IPY_MODEL_4336ef3ed7c84dc5800d44818e636ad2","value":" 44.7M/44.7M [00:00&lt;00:00, 109MB/s]"}},"367c1c2fd8dc4f53a86425fc81466451":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6f6abeb3a444085992b846d184aeb47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16904d3f67644c7d9e6ae77bca452a36":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6d5b81d0bfcc41258a7a8e101c6eab2e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d6e8856985a34894b8fca3ba6dec4830":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1a988bd12c5c48e1a33fb7d1e2902c50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4336ef3ed7c84dc5800d44818e636ad2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hTfUDjTm6wGn","executionInfo":{"status":"ok","timestamp":1651464798817,"user_tz":240,"elapsed":118,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}},"outputId":"df7c1b83-271f-40c9-f0c0-051c9957e290"},"outputs":[{"output_type":"stream","name":"stdout","text":["PyTorch Version:  1.11.0+cu113\n","Torchvision Version:  0.12.0+cu113\n"]}],"source":["from __future__ import print_function\n","from __future__ import division\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","import torchvision\n","from torchvision import datasets, models, transforms\n","import matplotlib.pyplot as plt\n","import pdb\n","import pandas as pd\n","from PIL import Image\n","import time\n","import os\n","import copy\n","import shutil\n","print(\"PyTorch Version: \",torch.__version__)\n","print(\"Torchvision Version: \",torchvision.__version__)"]},{"cell_type":"markdown","source":["## Download Data"],"metadata":{"id":"P2ry2lqo2W6F"}},{"cell_type":"code","source":["# Mount to GDrive to get data\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hIQFrfzALNvr","executionInfo":{"status":"ok","timestamp":1651464822527,"user_tz":240,"elapsed":22016,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}},"outputId":"131e1f09-80ae-4b37-ee4d-8c0265676b8d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Change this to your own Gdrive path to where the datasets lie in\n","mount_dir = '/content/drive/My\\ Drive/Harvard/2021-22\\ Spring\\ -\\ CS\\ 282r/CS\\ 282r\\ Final\\ Project'"],"metadata":{"id":"grdS08cmLpaM","executionInfo":{"status":"ok","timestamp":1651464822528,"user_tz":240,"elapsed":5,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Full segin 95 to 50 dataset\n","zipped_dataset = os.path.join(mount_dir, \"places_validation_waterbird_95_segin_full.zip\")\n","!unzip $zipped_dataset -d '/content/' "],"metadata":{"id":"1azvgpKLL_6b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Training\n","\n","Code inspired by PyTorch's baseline finetuning [code](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)."],"metadata":{"id":"MVy4alWXNnOg"}},{"cell_type":"code","source":["# Models to choose from [resnet, alexnet, vgg, squeezenet, densenet, inception]\n","model_name = \"resnet\"\n","\n","# Number of classes in the dataset\n","num_classes = 12\n","\n","# Batch size for training (change depending on how much memory you have)\n","batch_size = 8\n","\n","# Number of epochs to train for\n","num_epochs = 20\n","\n","# Flag for feature extracting. When False, we finetune the whole model,\n","#   when True we only update the reshaped layer params\n","feature_extract = True"],"metadata":{"id":"dBk7AmDyNnOg","executionInfo":{"status":"ok","timestamp":1651465299962,"user_tz":240,"elapsed":198,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def train_model(model, dataloaders, criterion, optimizer, num_epochs=25, is_inception=False):\n","    since = time.time()\n","\n","    val_acc_history = []\n","\n","    best_model_wts = copy.deepcopy(model.state_dict())\n","    best_acc = 0.0\n","\n","    for epoch in range(num_epochs):\n","        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n","        print('-' * 10)\n","\n","        # Each epoch has a training and validation phase\n","        for phase in ['train','val','test50','test55','test60','test65','test70','test75','test80','test85','test90','test95']:\n","            if phase == 'train':\n","                model.train()  # Set model to training mode\n","            else:\n","                model.eval()   # Set model to evaluate mode\n","\n","            running_loss = 0.0\n","            running_corrects = 0\n","\n","            # Iterate over data.\n","            for inputs, labels in dataloaders[phase]:\n","                inputs = inputs.to(device)\n","                labels = labels.to(device)\n","\n","                # zero the parameter gradients\n","                optimizer.zero_grad()\n","\n","                # forward\n","                # track history if only in train\n","                with torch.set_grad_enabled(phase == 'train'):\n","                    # Get model outputs and calculate loss\n","                    # Special case for inception because in training it has an auxiliary output. In train\n","                    #   mode we calculate the loss by summing the final output and the auxiliary output\n","                    #   but in testing we only consider the final output.\n","                    if is_inception and phase == 'train':\n","                        outputs, aux_outputs = model(inputs)\n","                        loss1 = criterion(outputs, labels)\n","                        loss2 = criterion(aux_outputs, labels)\n","                        loss = loss1 + 0.4*loss2\n","                    else:\n","                        outputs = model(inputs)\n","                        loss = criterion(outputs, labels)\n","\n","                    _, preds = torch.max(outputs, 1)\n","\n","                    # backward + optimize only if in training phase\n","                    if phase == 'train':\n","                        loss.backward()\n","                        optimizer.step()\n","\n","                # statistics\n","                running_loss += loss.item() * inputs.size(0)\n","                running_corrects += torch.sum(preds == labels.data)\n","\n","            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n","            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n","\n","            print('{} Loss: {:.4f} Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n","\n","            # deep copy the model\n","            if phase == 'val' and epoch_acc > best_acc:\n","                best_acc = epoch_acc\n","                best_model_wts = copy.deepcopy(model.state_dict())\n","            if phase == 'val':\n","                val_acc_history.append(epoch_acc)\n","\n","        print()\n","\n","    time_elapsed = time.time() - since\n","    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n","    print('Best val Acc: {:4f}'.format(best_acc))\n","\n","    # load best model weights\n","    model.load_state_dict(best_model_wts)\n","    return model, val_acc_history"],"metadata":{"id":"XlN1SPU-NnOh","executionInfo":{"status":"ok","timestamp":1651465352395,"user_tz":240,"elapsed":206,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def set_parameter_requires_grad(model, feature_extracting):\n","    if feature_extracting:\n","        for param in model.parameters():\n","            param.requires_grad = False"],"metadata":{"id":"yNoFWnyDNnOh","executionInfo":{"status":"ok","timestamp":1651465355094,"user_tz":240,"elapsed":222,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n","    # Initialize these variables which will be set in this if statement. Each of these\n","    #   variables is model specific.\n","    model_ft = None\n","    input_size = 0\n","\n","    # Downloads pretrained Resnet\n","    model_ft = models.resnet18(pretrained=use_pretrained)\n","    set_parameter_requires_grad(model_ft, feature_extract)\n","    num_ftrs = model_ft.fc.in_features\n","    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n","    input_size = 224\n","\n","    # Add 4th channel\n","    pretrained_weights = model_ft.conv1.weight.clone()\n","    model_ft.conv1 = nn.Conv2d(4,  # Add extra 2d conv for the 4-channel input\n","                               64, \n","                               kernel_size=7, \n","                               stride=2, \n","                               padding=3, \n","                               bias=False)\n","    \n","    model_ft.conv1.weight.data[:, :3] = pretrained_weights\n","    model_ft.conv1.weight.data[:, 3] = model_ft.conv1.weight.data[:, 0]\n","\n","    return model_ft, input_size\n","\n","# Initialize the model for this run\n","model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=True)\n","\n","# Print the model we just instantiated\n","print(model_ft)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["586ae0288fbc480fb676e67d97359198","510678b2049340b5b239768474bc9b4d","ad4f1c0bbe4f48b7b8ce69615ccbb330","c220bf1d60cd4c8b982d4d965677b784","367c1c2fd8dc4f53a86425fc81466451","e6f6abeb3a444085992b846d184aeb47","16904d3f67644c7d9e6ae77bca452a36","6d5b81d0bfcc41258a7a8e101c6eab2e","d6e8856985a34894b8fca3ba6dec4830","1a988bd12c5c48e1a33fb7d1e2902c50","4336ef3ed7c84dc5800d44818e636ad2"]},"executionInfo":{"status":"ok","timestamp":1651465360319,"user_tz":240,"elapsed":1183,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}},"outputId":"8434a018-3155-4ed6-a6b6-e09fa47520a5","id":"7TZ5vbSMNnOh"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"586ae0288fbc480fb676e67d97359198"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["ResNet(\n","  (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=12, bias=True)\n",")\n"]}]},{"cell_type":"markdown","source":["## Finetuning on Resnet50: 50 to 95 full\n"],"metadata":{"id":"u8H4BXZT0X7d"}},{"cell_type":"code","source":["data_dir = \"places_validation_waterbird_95_segin_full\""],"metadata":{"id":"wkjxIYIfy__5","executionInfo":{"status":"ok","timestamp":1651465371011,"user_tz":240,"elapsed":181,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# Data augmentation and normalization for training\n","# Just normalization for validation\n","test_transform = transforms.Compose([\n","        transforms.Resize(input_size),\n","        transforms.CenterCrop(input_size),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406, 0.5], [0.229, 0.224, 0.225, 0.5])\n","    ])\n","data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.RandomResizedCrop(input_size),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406, 0.5], [0.229, 0.224, 0.225, 0.5]) # alpha channel mean & std?\n","    ]),\n","    'val': test_transform,\n","    'test50': test_transform,\n","    'test55': test_transform,\n","    'test60': test_transform,\n","    'test65': test_transform,\n","    'test70': test_transform,\n","    'test75': test_transform,\n","    'test80': test_transform,\n","    'test85': test_transform,\n","    'test90': test_transform,\n","    'test95': test_transform\n","}\n","\n","print(\"Initializing Datasets and Dataloaders...\")\n","\n","# Create new loader that reads PNG alpha channel\n","def png_loader(path):\n","  return Image.open(path).convert('RGBA')\n","\n","# Create training and validation datasets\n","image_datasets = {x: datasets.ImageFolder(\n","                      os.path.join(data_dir, x), \n","                      data_transforms[x],\n","                      loader=png_loader) \\\n","                  for x in [\n","                            'train', \n","                            'val', \n","                            'test50',\n","                            'test55',\n","                            'test60',\n","                            'test65',\n","                            'test70',\n","                            'test75',\n","                            'test80',\n","                            'test85',\n","                            'test90',\n","                            'test95'\n","                            ]}\n","# Create training and validation dataloaders\n","dataloaders_dict = {x: torch.utils.data.DataLoader(\n","                        image_datasets[x], \n","                        batch_size=batch_size, \n","                        shuffle=True, \n","                        num_workers=4) \\\n","                    for x in [\n","                            'train', \n","                            'val', \n","                            'test50',\n","                            'test55',\n","                            'test60',\n","                            'test65',\n","                            'test70',\n","                            'test75',\n","                            'test80',\n","                            'test85',\n","                            'test90',\n","                            'test95'\n","                            ]}\n","\n","\n","# Detect if we have a GPU available\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TaZK2GsN0SYl","executionInfo":{"status":"ok","timestamp":1651465445424,"user_tz":240,"elapsed":436,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}},"outputId":"f948a82d-9d50-4d72-b9c0-c4c91d703d12"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Initializing Datasets and Dataloaders...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"code","source":["# Test dataloader image channels = 4\n","dtl = dataloaders_dict['train']\n","next(iter(dtl))[0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Wi1FDDMbyd5m","executionInfo":{"status":"ok","timestamp":1651465451076,"user_tz":240,"elapsed":863,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}},"outputId":"e12a7d5c-7e04-4aa0-f1ab-78a1236b7841"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 4, 224, 224])"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["# Send the model to GPU\n","model_ft = model_ft.to(device)\n","\n","# Gather the parameters to be optimized/updated in this run. If we are\n","#  finetuning we will be updating all parameters. However, if we are\n","#  doing feature extract method, we will only update the parameters\n","#  that we have just initialized, i.e. the parameters with requires_grad\n","#  is True.\n","params_to_update = model_ft.parameters()\n","print(\"Params to learn:\")\n","if feature_extract:\n","    params_to_update = []\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            params_to_update.append(param)\n","            print(\"\\t\",name)\n","else:\n","    for name,param in model_ft.named_parameters():\n","        if param.requires_grad == True:\n","            print(\"\\t\",name)\n","\n","# Observe that all parameters are being optimized\n","optimizer_ft = optim.SGD(params_to_update, lr=0.001, momentum=0.9)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"saKBP6Qq3vhk","executionInfo":{"status":"ok","timestamp":1651465464046,"user_tz":240,"elapsed":8490,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}},"outputId":"6386932c-ef01-465d-86f6-265e8e4fed7f"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Params to learn:\n","\t conv1.weight\n","\t fc.weight\n","\t fc.bias\n"]}]},{"cell_type":"code","source":["# Setup the loss function\n","criterion = nn.CrossEntropyLoss()\n","\n","# Train and evaluate\n","model_ft, hist = train_model(model_ft, \n","                             dataloaders_dict, \n","                             criterion, \n","                             optimizer_ft, \n","                             num_epochs=num_epochs, \n","                             is_inception=(model_name==\"inception\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjYCOn3R_B3a","outputId":"9165dfb4-82f9-4b73-d7a7-82790f9656d6","executionInfo":{"status":"ok","timestamp":1651479390844,"user_tz":240,"elapsed":13918482,"user":{"displayName":"Catherine Yeo","userId":"16343183467502936057"}}},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 0/19\n","----------\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["train Loss: 0.3744 Acc: 0.8430\n","val Loss: 0.1711 Acc: 0.9324\n","test50 Loss: 0.2951 Acc: 0.8819\n","test55 Loss: 0.2710 Acc: 0.8939\n","test60 Loss: 0.2617 Acc: 0.9037\n","test65 Loss: 0.2535 Acc: 0.9061\n","test70 Loss: 0.2458 Acc: 0.9084\n","test75 Loss: 0.2316 Acc: 0.9146\n","test80 Loss: 0.2212 Acc: 0.9165\n","test85 Loss: 0.2124 Acc: 0.9197\n","test90 Loss: 0.1947 Acc: 0.9310\n","test95 Loss: 0.1864 Acc: 0.9355\n","\n","Epoch 1/19\n","----------\n","train Loss: 0.3089 Acc: 0.8755\n","val Loss: 0.1657 Acc: 0.9441\n","test50 Loss: 0.2804 Acc: 0.8926\n","test55 Loss: 0.2624 Acc: 0.8952\n","test60 Loss: 0.2536 Acc: 0.9058\n","test65 Loss: 0.2450 Acc: 0.9077\n","test70 Loss: 0.2383 Acc: 0.9096\n","test75 Loss: 0.2190 Acc: 0.9197\n","test80 Loss: 0.2104 Acc: 0.9187\n","test85 Loss: 0.2029 Acc: 0.9277\n","test90 Loss: 0.1897 Acc: 0.9341\n","test95 Loss: 0.1783 Acc: 0.9337\n","\n","Epoch 2/19\n","----------\n","train Loss: 0.3276 Acc: 0.8682\n","val Loss: 0.2149 Acc: 0.9091\n","test50 Loss: 0.3804 Acc: 0.8367\n","test55 Loss: 0.3440 Acc: 0.8511\n","test60 Loss: 0.3310 Acc: 0.8623\n","test65 Loss: 0.3221 Acc: 0.8695\n","test70 Loss: 0.3054 Acc: 0.8775\n","test75 Loss: 0.2884 Acc: 0.8811\n","test80 Loss: 0.2733 Acc: 0.8904\n","test85 Loss: 0.2553 Acc: 0.8945\n","test90 Loss: 0.2388 Acc: 0.9059\n","test95 Loss: 0.2222 Acc: 0.9115\n","\n","Epoch 3/19\n","----------\n","train Loss: 0.3089 Acc: 0.8820\n","val Loss: 0.1632 Acc: 0.9450\n","test50 Loss: 0.2626 Acc: 0.9103\n","test55 Loss: 0.2427 Acc: 0.9108\n","test60 Loss: 0.2358 Acc: 0.9194\n","test65 Loss: 0.2342 Acc: 0.9192\n","test70 Loss: 0.2257 Acc: 0.9222\n","test75 Loss: 0.2112 Acc: 0.9244\n","test80 Loss: 0.2030 Acc: 0.9298\n","test85 Loss: 0.1971 Acc: 0.9330\n","test90 Loss: 0.1870 Acc: 0.9370\n","test95 Loss: 0.1736 Acc: 0.9415\n","\n","Epoch 4/19\n","----------\n","train Loss: 0.2985 Acc: 0.8874\n","val Loss: 0.1825 Acc: 0.9308\n","test50 Loss: 0.3224 Acc: 0.8706\n","test55 Loss: 0.2897 Acc: 0.8847\n","test60 Loss: 0.2802 Acc: 0.8901\n","test65 Loss: 0.2697 Acc: 0.8983\n","test70 Loss: 0.2571 Acc: 0.8982\n","test75 Loss: 0.2418 Acc: 0.9078\n","test80 Loss: 0.2297 Acc: 0.9140\n","test85 Loss: 0.2166 Acc: 0.9180\n","test90 Loss: 0.2038 Acc: 0.9232\n","test95 Loss: 0.1895 Acc: 0.9325\n","\n","Epoch 5/19\n","----------\n","train Loss: 0.2798 Acc: 0.8938\n","val Loss: 0.1720 Acc: 0.9366\n","test50 Loss: 0.2796 Acc: 0.8937\n","test55 Loss: 0.2546 Acc: 0.9014\n","test60 Loss: 0.2527 Acc: 0.9037\n","test65 Loss: 0.2453 Acc: 0.9092\n","test70 Loss: 0.2318 Acc: 0.9123\n","test75 Loss: 0.2172 Acc: 0.9173\n","test80 Loss: 0.2072 Acc: 0.9230\n","test85 Loss: 0.2027 Acc: 0.9253\n","test90 Loss: 0.1847 Acc: 0.9330\n","test95 Loss: 0.1802 Acc: 0.9320\n","\n","Epoch 6/19\n","----------\n","train Loss: 0.3154 Acc: 0.8797\n","val Loss: 0.1900 Acc: 0.9299\n","test50 Loss: 0.3353 Acc: 0.8654\n","test55 Loss: 0.3129 Acc: 0.8718\n","test60 Loss: 0.3054 Acc: 0.8756\n","test65 Loss: 0.2937 Acc: 0.8813\n","test70 Loss: 0.2716 Acc: 0.8914\n","test75 Loss: 0.2613 Acc: 0.8907\n","test80 Loss: 0.2410 Acc: 0.9027\n","test85 Loss: 0.2296 Acc: 0.9103\n","test90 Loss: 0.2150 Acc: 0.9201\n","test95 Loss: 0.2049 Acc: 0.9222\n","\n","Epoch 7/19\n","----------\n","train Loss: 0.3062 Acc: 0.8822\n","val Loss: 0.1609 Acc: 0.9383\n","test50 Loss: 0.2617 Acc: 0.9037\n","test55 Loss: 0.2455 Acc: 0.9106\n","test60 Loss: 0.2341 Acc: 0.9191\n","test65 Loss: 0.2294 Acc: 0.9215\n","test70 Loss: 0.2199 Acc: 0.9242\n","test75 Loss: 0.2084 Acc: 0.9272\n","test80 Loss: 0.2038 Acc: 0.9273\n","test85 Loss: 0.1946 Acc: 0.9308\n","test90 Loss: 0.1812 Acc: 0.9356\n","test95 Loss: 0.1741 Acc: 0.9425\n","\n","Epoch 8/19\n","----------\n","train Loss: 0.2946 Acc: 0.8790\n","val Loss: 0.1622 Acc: 0.9358\n","test50 Loss: 0.2823 Acc: 0.8961\n","test55 Loss: 0.2591 Acc: 0.9023\n","test60 Loss: 0.2506 Acc: 0.9051\n","test65 Loss: 0.2451 Acc: 0.9071\n","test70 Loss: 0.2322 Acc: 0.9166\n","test75 Loss: 0.2200 Acc: 0.9194\n","test80 Loss: 0.2115 Acc: 0.9225\n","test85 Loss: 0.2026 Acc: 0.9284\n","test90 Loss: 0.1877 Acc: 0.9298\n","test95 Loss: 0.1786 Acc: 0.9367\n","\n","Epoch 9/19\n","----------\n","train Loss: 0.2813 Acc: 0.8922\n","val Loss: 0.1851 Acc: 0.9274\n","test50 Loss: 0.3105 Acc: 0.8776\n","test55 Loss: 0.2865 Acc: 0.8854\n","test60 Loss: 0.2730 Acc: 0.8937\n","test65 Loss: 0.2647 Acc: 0.8944\n","test70 Loss: 0.2485 Acc: 0.9035\n","test75 Loss: 0.2299 Acc: 0.9108\n","test80 Loss: 0.2247 Acc: 0.9139\n","test85 Loss: 0.2165 Acc: 0.9180\n","test90 Loss: 0.1938 Acc: 0.9234\n","test95 Loss: 0.1844 Acc: 0.9323\n","\n","Epoch 10/19\n","----------\n","train Loss: 0.3039 Acc: 0.8847\n","val Loss: 0.5215 Acc: 0.7773\n","test50 Loss: 0.7708 Acc: 0.6855\n","test55 Loss: 0.7186 Acc: 0.7002\n","test60 Loss: 0.7186 Acc: 0.7052\n","test65 Loss: 0.6763 Acc: 0.7195\n","test70 Loss: 0.6427 Acc: 0.7325\n","test75 Loss: 0.6185 Acc: 0.7346\n","test80 Loss: 0.5899 Acc: 0.7563\n","test85 Loss: 0.5741 Acc: 0.7594\n","test90 Loss: 0.5345 Acc: 0.7772\n","test95 Loss: 0.5278 Acc: 0.7758\n","\n","Epoch 11/19\n","----------\n","train Loss: 0.2802 Acc: 0.8893\n","val Loss: 0.2288 Acc: 0.9091\n","test50 Loss: 0.3734 Acc: 0.8478\n","test55 Loss: 0.3436 Acc: 0.8605\n","test60 Loss: 0.3342 Acc: 0.8673\n","test65 Loss: 0.3281 Acc: 0.8693\n","test70 Loss: 0.3040 Acc: 0.8813\n","test75 Loss: 0.2896 Acc: 0.8821\n","test80 Loss: 0.2780 Acc: 0.8920\n","test85 Loss: 0.2638 Acc: 0.8906\n","test90 Loss: 0.2437 Acc: 0.9052\n","test95 Loss: 0.2342 Acc: 0.9087\n","\n","Epoch 12/19\n","----------\n","train Loss: 0.2942 Acc: 0.8813\n","val Loss: 0.1639 Acc: 0.9374\n","test50 Loss: 0.2815 Acc: 0.8992\n","test55 Loss: 0.2586 Acc: 0.9011\n","test60 Loss: 0.2513 Acc: 0.9115\n","test65 Loss: 0.2423 Acc: 0.9137\n","test70 Loss: 0.2302 Acc: 0.9196\n","test75 Loss: 0.2176 Acc: 0.9232\n","test80 Loss: 0.2133 Acc: 0.9223\n","test85 Loss: 0.1996 Acc: 0.9284\n","test90 Loss: 0.1864 Acc: 0.9342\n","test95 Loss: 0.1733 Acc: 0.9411\n","\n","Epoch 13/19\n","----------\n","train Loss: 0.2812 Acc: 0.8886\n","val Loss: 0.1842 Acc: 0.9383\n","test50 Loss: 0.2665 Acc: 0.9030\n","test55 Loss: 0.2486 Acc: 0.9042\n","test60 Loss: 0.2430 Acc: 0.9111\n","test65 Loss: 0.2410 Acc: 0.9104\n","test70 Loss: 0.2216 Acc: 0.9203\n","test75 Loss: 0.2097 Acc: 0.9247\n","test80 Loss: 0.2076 Acc: 0.9253\n","test85 Loss: 0.1960 Acc: 0.9291\n","test90 Loss: 0.1849 Acc: 0.9323\n","test95 Loss: 0.1739 Acc: 0.9373\n","\n","Epoch 14/19\n","----------\n","train Loss: 0.2886 Acc: 0.8884\n","val Loss: 0.1622 Acc: 0.9458\n","test50 Loss: 0.2620 Acc: 0.9061\n","test55 Loss: 0.2449 Acc: 0.9078\n","test60 Loss: 0.2369 Acc: 0.9165\n","test65 Loss: 0.2294 Acc: 0.9159\n","test70 Loss: 0.2230 Acc: 0.9213\n","test75 Loss: 0.2129 Acc: 0.9220\n","test80 Loss: 0.2134 Acc: 0.9244\n","test85 Loss: 0.1989 Acc: 0.9272\n","test90 Loss: 0.1868 Acc: 0.9334\n","test95 Loss: 0.1785 Acc: 0.9375\n","\n","Epoch 15/19\n","----------\n","train Loss: 0.2848 Acc: 0.8924\n","val Loss: 0.2069 Acc: 0.9208\n","test50 Loss: 0.3509 Acc: 0.8571\n","test55 Loss: 0.3220 Acc: 0.8659\n","test60 Loss: 0.3108 Acc: 0.8723\n","test65 Loss: 0.2997 Acc: 0.8756\n","test70 Loss: 0.2772 Acc: 0.8864\n","test75 Loss: 0.2716 Acc: 0.8899\n","test80 Loss: 0.2568 Acc: 0.8939\n","test85 Loss: 0.2430 Acc: 0.9006\n","test90 Loss: 0.2197 Acc: 0.9144\n","test95 Loss: 0.2090 Acc: 0.9151\n","\n","Epoch 16/19\n","----------\n","train Loss: 0.3032 Acc: 0.8818\n","val Loss: 0.1512 Acc: 0.9483\n","test50 Loss: 0.2577 Acc: 0.9066\n","test55 Loss: 0.2392 Acc: 0.9089\n","test60 Loss: 0.2335 Acc: 0.9178\n","test65 Loss: 0.2255 Acc: 0.9211\n","test70 Loss: 0.2180 Acc: 0.9235\n","test75 Loss: 0.2016 Acc: 0.9260\n","test80 Loss: 0.2009 Acc: 0.9306\n","test85 Loss: 0.1901 Acc: 0.9349\n","test90 Loss: 0.1791 Acc: 0.9403\n","test95 Loss: 0.1730 Acc: 0.9396\n","\n","Epoch 17/19\n","----------\n","train Loss: 0.2863 Acc: 0.8876\n","val Loss: 0.1600 Acc: 0.9399\n","test50 Loss: 0.2809 Acc: 0.8894\n","test55 Loss: 0.2566 Acc: 0.8987\n","test60 Loss: 0.2527 Acc: 0.9030\n","test65 Loss: 0.2339 Acc: 0.9101\n","test70 Loss: 0.2277 Acc: 0.9147\n","test75 Loss: 0.2124 Acc: 0.9192\n","test80 Loss: 0.2058 Acc: 0.9237\n","test85 Loss: 0.1945 Acc: 0.9260\n","test90 Loss: 0.1813 Acc: 0.9356\n","test95 Loss: 0.1737 Acc: 0.9336\n","\n","Epoch 18/19\n","----------\n","train Loss: 0.2851 Acc: 0.8913\n","val Loss: 0.1725 Acc: 0.9383\n","test50 Loss: 0.3175 Acc: 0.8726\n","test55 Loss: 0.2921 Acc: 0.8832\n","test60 Loss: 0.2776 Acc: 0.8925\n","test65 Loss: 0.2651 Acc: 0.8973\n","test70 Loss: 0.2539 Acc: 0.9018\n","test75 Loss: 0.2369 Acc: 0.9073\n","test80 Loss: 0.2274 Acc: 0.9128\n","test85 Loss: 0.2128 Acc: 0.9144\n","test90 Loss: 0.1975 Acc: 0.9215\n","test95 Loss: 0.1886 Acc: 0.9253\n","\n","Epoch 19/19\n","----------\n","train Loss: 0.2888 Acc: 0.8863\n","val Loss: 0.1725 Acc: 0.9341\n","test50 Loss: 0.2728 Acc: 0.8947\n","test55 Loss: 0.2562 Acc: 0.9008\n","test60 Loss: 0.2486 Acc: 0.9056\n","test65 Loss: 0.2411 Acc: 0.9037\n","test70 Loss: 0.2318 Acc: 0.9113\n","test75 Loss: 0.2167 Acc: 0.9194\n","test80 Loss: 0.2125 Acc: 0.9196\n","test85 Loss: 0.2017 Acc: 0.9244\n","test90 Loss: 0.1921 Acc: 0.9241\n","test95 Loss: 0.1870 Acc: 0.9296\n","\n","Training complete in 231m 58s\n","Best val Acc: 0.948290\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"0HsdRDCoS4mq"},"execution_count":null,"outputs":[]}]}